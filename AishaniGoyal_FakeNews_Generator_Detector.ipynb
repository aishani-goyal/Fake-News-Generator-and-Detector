{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### üì∞ **Project Description: Fake News Generator & Detector using Generative AI and NLP**\n",
        "This project is an interactive AI-powered tool that enables users to both generate realistic-looking fake news articles and detect whether a given news text is fake or real using state-of-the-art natural language processing models. It highlights how language models can both create and combat misinformation.\n",
        "\n",
        "üß∞ **The application is built using:**\n",
        "\n",
        "1. **Transformers Library (by Hugging Face)**:\n",
        "For loading and using pretrained models ‚Äî GPT-2 for fake news generation and fine-tuned BERT for fake news detection.\n",
        "\n",
        "2. **Gradio:** To create a simple, interactive web-based user interface with tabbed sections for generation and detection.\n",
        "\n",
        "3. **Google Colab / Python:** For backend development, prototyping, and running the application in a cloud-based notebook environment.\n",
        "\n",
        "üéØ **Project Objectives**\n",
        "\n",
        "**1. Generate Fake News Text**\n",
        "\n",
        "Use GPT-2 to simulate fake news articles from user-provided prompts for for awareness and experimentation.\n",
        "\n",
        "**2. Detect Fake or Real News**\n",
        "\n",
        "Utilize a fine-tuned BERT model (Pulk17/Fake-News-Detection) to accurately classify news content as fake or real.\n",
        "\n",
        "**3. Provide an Interactive Interface**\n",
        "\n",
        "Use Gradio to build a user-friendly web interface.\n",
        "\n",
        "**4. Demonstrate Dual Use of AI in Misinformation**\n",
        "\n",
        "Showcase how AI can both create and detect fake news, promoting awareness and responsible AI usage.\n",
        "\n",
        "\n",
        "## üîó Live Demo\n",
        "üëâ [Click here to try the app on Hugging Face Spaces](https://huggingface.co/spaces/Aishani03/Fake_News_Generator_Detector)"
      ],
      "metadata": {
        "id": "hHu6m-af9Sn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Install Required Libraries**\n",
        "\n",
        "Installing the transformers, torch, and gradio libraries to work with pretrained models and UI."
      ],
      "metadata": {
        "id": "z9BIs9r8ytD6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UksMKS7IxBgi"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q transformers torch gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Import Required Modules**\n",
        "\n",
        " Import libraries for model handling, tokenization, and interface building."
      ],
      "metadata": {
        "id": "QmYnFkhky-IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "XO8sFocTxEk0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Check for GPU Availability**\n",
        "\n",
        "Check and assign computation device ‚Äî GPU if available, otherwise CPU."
      ],
      "metadata": {
        "id": "uQoCtm9ZzNNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Fx7oe4z9zKjs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Load Pretrained GPT-2 and BERT Models**\n",
        "\n",
        "Load GPT-2 for fake news generation and BERT for fake news detection."
      ],
      "metadata": {
        "id": "4apM7yMDzcUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GPT-2 model and tokenizer\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
        "\n",
        "# Load fine-tuned BERT model and tokenizer for Fake News Detection\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"Pulk17/Fake-News-Detection\")\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"Pulk17/Fake-News-Detection\"\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "iFsROfD3zilc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Define Fake News Generator Function**\n",
        "\n",
        "Create a function using GPT-2 that generates fake news based on a given prompt."
      ],
      "metadata": {
        "id": "fylqSh7Bz28d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fake news generator\n",
        "def generate_fake_news(prompt):\n",
        "    inputs = gpt2_tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    outputs = gpt2_model.generate(\n",
        "        inputs,\n",
        "        max_length=200,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    generated_text = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "tYPOaBoazn2W"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Define News Detection Function**\n",
        "\n",
        "Use BERT to classify news as \"Fake\" or \"Real\" based on the model‚Äôs prediction."
      ],
      "metadata": {
        "id": "7ZxaqDIn0L2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# News classification (fake/real)\n",
        "def detect_news(text):\n",
        "    inputs = bert_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "    confidence = torch.softmax(logits, dim=1)[0][predicted_class].item()\n",
        "    label = \"üü• Fake News\" if predicted_class == 0 else \"üü© Real News\"\n",
        "    return f\"{label} (Confidence: {confidence:.2f})\""
      ],
      "metadata": {
        "id": "_lXKorWO0JUA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Build Gradio UI**\n",
        "\n",
        "Design a web interface with two tabs ‚Äî one for generation and one for detection."
      ],
      "metadata": {
        "id": "JxEqrcwP0ZtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üì∞ Fake News Generator & Detector (GPT-2 + BERT)\")\n",
        "\n",
        "    with gr.Tab(\"üõ†Ô∏è Generate Fake News\"):\n",
        "        with gr.Row():\n",
        "            input_text = gr.Textbox(\n",
        "                label=\"Enter a News Headline or Prompt\",\n",
        "                placeholder=\"e.g. Scientists discover a talking dolphin species near Japan...\",\n",
        "                lines=2\n",
        "            )\n",
        "        generate_btn = gr.Button(\"Generate\")\n",
        "        output_text = gr.Textbox(label=\"Generated News Article\")\n",
        "        generate_btn.click(generate_fake_news, inputs=input_text, outputs=output_text)\n",
        "\n",
        "    with gr.Tab(\"üîç Detect Fake or Real\"):\n",
        "        with gr.Row():\n",
        "            detect_input = gr.Textbox(\n",
        "                label=\"Enter a News Article or Statement\",\n",
        "                placeholder=\"Paste a paragraph to detect if it's fake or real...\",\n",
        "                lines=5\n",
        "            )\n",
        "        detect_btn = gr.Button(\"Detect\")\n",
        "        detect_output = gr.Textbox(label=\"Detection Result\")\n",
        "        detect_btn.click(detect_news, inputs=detect_input, outputs=detect_output)\n"
      ],
      "metadata": {
        "id": "1ls8_6zs0Q_z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Launch the App**"
      ],
      "metadata": {
        "id": "acjjiZbQ0g7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the Gradio app\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "sH-wPoj60eKd",
        "outputId": "796b68af-a132-4bf2-c3b4-d34cb66217dc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://71e2cbdfd72886b3b6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://71e2cbdfd72886b3b6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WDUZNvqD0tDY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}